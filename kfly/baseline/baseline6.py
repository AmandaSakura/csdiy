# ==============================================================================
# BASELINE 6 - Pseudo-Labeling
# ==============================================================================
# - Implements Pseudo-Labeling, a semi-supervised learning technique.
# - STAGE 1: Train a strong base model on the original data.
# - STAGE 2: Use the base model to predict on the test set and generate pseudo-labels
#            for high-confidence predictions.
# - STAGE 3: Combine original data with pseudo-labeled data.
# - STAGE 4: Retrain a final model on the enriched dataset.
# ==============================================================================

import pandas as pd
import numpy as np
import json
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, classification_report
from datetime import datetime
import warnings
import os

# ç¡®ä¿ imbalanced-learn å·²å®‰è£…
try:
    from imblearn.under_sampling import RandomUnderSampler
    print("âœ… imbalanced-learn åº“å·²æˆåŠŸå¯¼å…¥ã€‚")
except ImportError:
    print("âŒ é”™è¯¯: æœªæ‰¾åˆ° imbalanced-learn åº“ã€‚è¯·å…ˆå®‰è£…ï¼špip install -U imbalanced-learn")
    exit()

warnings.filterwarnings('ignore')

# --- 0. å…¨å±€é…ç½® (Global Configuration) ---
# è·¯å¾„é…ç½®
DATA_DIR = "/home/joker/new_csdiylearning2/kfly/data"
SAVE_DIR = "/home/joker/new_csdiylearning2/kfly/data/baseline6" # <--- å·²æ›´æ–°ä¸º baseline6 è·¯å¾„
os.makedirs(SAVE_DIR, exist_ok=True)

# æ¨¡å‹ä¸ä¼ªæ ‡ç­¾é…ç½®
UNDERSAMPLING_RATIO = 0.5
N_FOLDS = 5
PSEUDO_LABEL_THRESH_HIGH = 0.99  # é«˜äºæ­¤æ¦‚ç‡çš„æµ‹è¯•é›†æ ·æœ¬å°†è¢«èµ‹äºˆ '1' çš„ä¼ªæ ‡ç­¾
PSEUDO_LABEL_THRESH_LOW = 0.01   # ä½äºæ­¤æ¦‚ç‡çš„æµ‹è¯•é›†æ ·æœ¬å°†è¢«èµ‹äºˆ '0' çš„ä¼ªæ ‡ç­¾

# ä½¿ç”¨æ‚¨åœ¨ baseline5 ä¸­æ‰¾åˆ°çš„æœ€ä½³å‚æ•°ï¼Œå¦‚æœéœ€è¦é‡æ–°è°ƒä¼˜ï¼Œå¯ä»¥å¼•å…¥Optuna
# è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å·²çŸ¥æœ€ä¼˜å‚æ•°æ¥æ¼”ç¤ºä¼ªæ ‡ç­¾æµç¨‹
BEST_PARAMS = {
    'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt',
    'verbosity': -1, 'random_state': 42, 'device': 'cuda',
    # ä»¥ä¸‹å‚æ•°åº”æ›¿æ¢ä¸ºæ‚¨åœ¨baseline5ä¸­æ‰¾åˆ°çš„æœ€ä½³å‚æ•°
    'num_leaves': 150, 'learning_rate': 0.1621265071250267, 
    'feature_fraction': 0.6986396182085532, 'bagging_fraction': 0.7310681715909233,
    'bagging_freq': 3, 'min_child_samples': 65, 
    'lambda_l1': 0.35743521920907556, 'lambda_l2': 0.03169483892100607
}

# --- 1. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (ä¸baseline5ç›¸åŒ) ---
def translateCsvToDf(filepath, dtypes=None): return pd.read_csv(filepath, dtype=dtypes)
def feature_engineering(train_df, test_df):
    """ç‰¹å¾å·¥ç¨‹ä¸»å‡½æ•° - ä½¿ç”¨ baseline5 çš„ç‰ˆæœ¬"""
    print("\n=== [STAGE 0/4] å¼€å§‹ç‰¹å¾å·¥ç¨‹ (æ²¿ç”¨Baseline5) ===")
    full_df = pd.concat([train_df.drop('is_new_did', axis=1, errors='ignore'), test_df], ignore_index=True)
    full_df['common_ts_dt'] = pd.to_datetime(full_df['common_ts'], unit='ms')
    full_df = full_df.sort_values(by=['did', 'common_ts_dt']).reset_index(drop=True)
    did_stats = full_df.groupby('did').agg(
        mid_count=('mid', 'count'), eid_nunique=('eid', 'nunique'),
        common_ts_min=('common_ts_dt', 'first'), common_ts_max=('common_ts_dt', 'last'),
        first_eid=('eid', 'first')
    ).reset_index()
    did_stats['ts_span'] = (did_stats['common_ts_max'] - did_stats['common_ts_min']).dt.total_seconds()
    full_df['event_rank'] = full_df.groupby('did').cumcount() + 1
    full_df = full_df.merge(did_stats[['did', 'common_ts_min', 'first_eid']], on='did', how='left')
    full_df['time_since_first'] = (full_df['common_ts_dt'] - full_df['common_ts_min']).dt.total_seconds()
    def process_chunk(df, full_processed_df):
        df['botId'] = np.nan; df['pluginId'] = np.nan
        for idx, udmap_str in df['udmap'].items():
            if pd.isna(udmap_str): continue
            try:
                udmap_dict = json.loads(udmap_str)
                if 'botId' in udmap_dict: df.loc[idx, 'botId'] = udmap_dict['botId']
                if 'pluginId' in udmap_dict: df.loc[idx, 'pluginId'] = udmap_dict['pluginId']
            except: continue
        df = df.reset_index().merge(full_processed_df, on=['did', 'common_ts'], how='left', suffixes=('', '_y')).set_index('index')
        df.drop([col for col in df.columns if '_y' in col], axis=1, inplace=True)
        for col in ['botId', 'pluginId', 'first_eid']:
            if col in df.columns: df[col] = df[col].fillna(-1).astype('int32')
        return df
    features_to_merge = full_df[['did', 'common_ts', 'event_rank', 'first_eid', 'time_since_first']]
    train_processed = process_chunk(train_df, features_to_merge).merge(did_stats.drop(['common_ts_min', 'common_ts_max', 'first_eid'], axis=1), on='did', how='left')
    test_processed = process_chunk(test_df, features_to_merge).merge(did_stats.drop(['common_ts_min', 'common_ts_max', 'first_eid'], axis=1), on='did', how='left')
    print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆã€‚")
    return train_processed, test_processed
def find_best_f1_threshold(y_true, y_pred):
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)
    f1_scores = 2 * recall * precision / (recall + precision + 1e-8)
    f1_scores = np.nan_to_num(f1_scores)
    best_idx = np.argmax(f1_scores)
    return thresholds[best_idx], f1_scores[best_idx]

# --- 2. æ•°æ®åŠ è½½ä¸å‡†å¤‡ ---
print("ä»£ç å¼€å§‹æ‰§è¡Œ...")
OringinTrainDataUrl = os.path.join(DATA_DIR, "train_data/train.csv")
OringinTestDataUrl = os.path.join(DATA_DIR, "test_data/testA_data.csv")
train_df = translateCsvToDf(OringinTrainDataUrl)
test_df = translateCsvToDf(OringinTestDataUrl)

train_df, test_df = feature_engineering(train_df, test_df)

exclude_features = ['did', 'udmap', 'common_ts', 'common_ts_dt', 'is_new_did']
feature_cols = [col for col in train_df.columns if col not in exclude_features]
X = train_df[feature_cols]
y = train_df['is_new_did']
X_test = test_df[feature_cols]

for col in X.select_dtypes(['int8', 'int16', 'int32']).columns:
    X[col] = X[col].astype('category')
    X_test[col] = X_test[col].astype('category')

# --- 3. ä¼ªæ ‡ç­¾æµç¨‹ ---
# STAGE 1: è®­ç»ƒåˆå§‹æ¨¡å‹å¹¶ç”ŸæˆOOFé¢„æµ‹ï¼ˆç”¨äºåç»­è¯„ä¼°ï¼‰å’Œæµ‹è¯•é›†é¢„æµ‹ï¼ˆç”¨äºç”Ÿæˆä¼ªæ ‡ç­¾ï¼‰
print("\n=== [STAGE 1/4] è®­ç»ƒåˆå§‹æ¨¡å‹ ===")
skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)
initial_oof_preds = np.zeros(len(X))
initial_test_preds = np.zeros(len(X_test))

for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
    print(f"--- åˆå§‹æ¨¡å‹ Fold {fold + 1}/{N_FOLDS} ---")
    X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]
    X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]
    
    rus = RandomUnderSampler(sampling_strategy=UNDERSAMPLING_RATIO, random_state=42)
    X_train_resampled, y_train_resampled = rus.fit_resample(X_train_fold, y_train_fold)
    
    model = lgb.train(BEST_PARAMS, lgb.Dataset(X_train_resampled, label=y_train_resampled, categorical_feature='auto'),
                      num_boost_round=3000, callbacks=[lgb.early_stopping(200, verbose=False)])
    
    initial_oof_preds[val_idx] = model.predict(X_val_fold)
    initial_test_preds += model.predict(X_test) / N_FOLDS

# STAGE 2: ç”Ÿæˆä¼ªæ ‡ç­¾
print("\n=== [STAGE 2/4] ç”Ÿæˆä¼ªæ ‡ç­¾ ===")
pseudo_labels_high = test_df[initial_test_preds > PSEUDO_LABEL_THRESH_HIGH].copy()
pseudo_labels_high['is_new_did'] = 1
pseudo_labels_low = test_df[initial_test_preds < PSEUDO_LABEL_THRESH_LOW].copy()
pseudo_labels_low['is_new_did'] = 0

pseudo_df = pd.concat([pseudo_labels_high, pseudo_labels_low], ignore_index=True)
print(f"âœ… ç”Ÿæˆäº† {len(pseudo_df)} æ¡é«˜ç½®ä¿¡åº¦ä¼ªæ ‡ç­¾ (æ­£ä¾‹: {len(pseudo_labels_high)}, è´Ÿä¾‹: {len(pseudo_labels_low)})")

# STAGE 3: åˆå¹¶æ•°æ®
print("\n=== [STAGE 3/4] åˆå¹¶åŸå§‹æ•°æ®ä¸ä¼ªæ ‡ç­¾æ•°æ® ===")
X_pseudo = pseudo_df[feature_cols]
y_pseudo = pseudo_df['is_new_did']

# è½¬æ¢ä¼ªæ ‡ç­¾æ•°æ®çš„ç±»åˆ«ç‰¹å¾
for col in X_pseudo.select_dtypes(['int8', 'int16', 'int32']).columns:
    X_pseudo[col] = X_pseudo[col].astype('category')

X_combined = pd.concat([X, X_pseudo], ignore_index=True)
y_combined = pd.concat([y, y_pseudo], ignore_index=True)
print(f"æ–°è®­ç»ƒé›†å¤§å°: {X_combined.shape}, ç±»åˆ«åˆ†å¸ƒ:\n{y_combined.value_counts()}")

# STAGE 4: åœ¨å¢å¼ºæ•°æ®é›†ä¸Šé‡æ–°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
print("\n=== [STAGE 4/4] åœ¨å¢å¼ºæ•°æ®é›†ä¸Šé‡æ–°è®­ç»ƒæœ€ç»ˆæ¨¡å‹ ===")
final_test_preds = np.zeros(len(X_test))
for fold, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined)):
    print(f"--- æœ€ç»ˆæ¨¡å‹ Fold {fold + 1}/{N_FOLDS} ---")
    X_train_fold, y_train_fold = X_combined.iloc[train_idx], y_combined.iloc[train_idx]
    
    # åŒæ ·è¿›è¡Œæ¬ é‡‡æ ·
    rus = RandomUnderSampler(sampling_strategy=UNDERSAMPLING_RATIO, random_state=42)
    X_train_resampled, y_train_resampled = rus.fit_resample(X_train_fold, y_train_fold)
    
    model = lgb.train(BEST_PARAMS, lgb.Dataset(X_train_resampled, label=y_train_resampled, categorical_feature='auto'),
                      num_boost_round=3000, callbacks=[lgb.early_stopping(200, verbose=False)])
    
    final_test_preds += model.predict(X_test) / N_FOLDS

# --- 4. è¯„ä¼°ä¸ä¿å­˜ ---
print("\n=== æ¨¡å‹è¯„ä¼° (åŸºäºåŸå§‹æ•°æ®çš„OOF) ===")
oof_best_threshold, oof_best_f1 = find_best_f1_threshold(y, initial_oof_preds)
print(f"åˆå§‹æ¨¡å‹OOF F1åˆ†æ•°: {oof_best_f1:.6f} (åœ¨é˜ˆå€¼ {oof_best_threshold:.4f} æ—¶å–å¾—)")
print("\nåˆå§‹æ¨¡å‹OOF åˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y, (initial_oof_preds >= oof_best_threshold).astype(int), digits=4))

print("\n=== ç”Ÿæˆå¹¶ä¿å­˜æœ€ç»ˆç»“æœ ===")
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

submission = pd.DataFrame({'did': test_df['did']})
# ä½¿ç”¨åˆå§‹æ¨¡å‹OOFè®¡ç®—å‡ºçš„æœ€ä½³é˜ˆå€¼
submission['is_new_did'] = (final_test_preds >= oof_best_threshold).astype(int)
submission_filename = os.path.join(SAVE_DIR, f"submission_b6_pseudolabel_{timestamp}.csv")
submission.to_csv(submission_filename, index=False)
print(f"ğŸ“„ é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {submission_filename}")
print("é¢„æµ‹ç»“æœç±»åˆ«åˆ†å¸ƒ:\n", submission['is_new_did'].value_counts(normalize=True))

print("\nğŸ‰ å…¨éƒ¨æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")