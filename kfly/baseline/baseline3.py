import pandas as pd
import numpy as np
import json
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, f1_score, precision_recall_curve
from datetime import datetime
import warnings
import optuna
import os
warnings.filterwarnings('ignore')

def translateCsvToDf(filepath, dtypes=None):
    return pd.read_csv(filepath, dtype=dtypes)

# --- 1. GPUç¯å¢ƒæ£€æŸ¥å’Œæ•°æ®åŠ è½½ ---
print("ä»£ç å¼€å§‹æ‰§è¡Œ...")

# æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
try:
    import lightgbm as lgb
    # åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•æ•°æ®é›†æ¥æ£€æŸ¥GPU
    test_X = np.random.rand(100, 5)
    test_y = np.random.randint(0, 2, 100)
    test_data = lgb.Dataset(test_X, label=test_y)
    
    test_params = {
        'objective': 'binary',
        'device': 'cuda',
        'gpu_platform_id': 0,
        'gpu_device_id': 0,
        'verbosity': -1
    }
    
    # å°è¯•ä½¿ç”¨GPUè®­ç»ƒ
    test_model = lgb.train(test_params, test_data, num_boost_round=1, verbose_eval=False)
    print("âœ… GPUåŠ é€Ÿå¯ç”¨ï¼Œå°†ä½¿ç”¨GPUè®­ç»ƒLightGBM")
    GPU_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ: {e}")
    print("å¦‚éœ€ä½¿ç”¨GPUï¼Œè¯·ç¡®ä¿ï¼š")
    print("1. å®‰è£…äº†æ”¯æŒGPUçš„LightGBMç‰ˆæœ¬")
    print("2. ç³»ç»Ÿæœ‰å¯ç”¨çš„GPUå’ŒOpenCLé©±åŠ¨")
    print("3. æ£€æŸ¥gpu_platform_idå’Œgpu_device_idè®¾ç½®")
    GPU_AVAILABLE = False
dtype_mapping = {
    'mid': 'int32', 'eid': 'int32', 'device_brand': 'int16', 'ntt': 'int8',
    'operator': 'int8', 'common_country': 'int16', 'common_province': 'int16',
    'common_city': 'int16', 'appver': 'int16', 'channel': 'int16',
    'os_type': 'int8', 'is_new_did': 'int8'
}

OringinTrainDataUrl = r"/home/joker/new_csdiylearning2/kfly/data/train_data/train.csv"
OringinTestDataUrl = r"/home/joker/new_csdiylearning2/kfly/data/test_data/testA_data.csv"

print("åŠ è½½è®­ç»ƒæ•°æ®...")
train_df = translateCsvToDf(OringinTrainDataUrl, dtypes=dtype_mapping)
print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_df.shape}")

print("åŠ è½½æµ‹è¯•æ•°æ®...")
test_df = translateCsvToDf(OringinTestDataUrl)
# æµ‹è¯•æ•°æ®ä¸åŒ…å«ç›®æ ‡å˜é‡ï¼Œæ‰€ä»¥ä¸åœ¨dtype_mappingä¸­æŒ‡å®š
print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_df.shape}")

# --- 2. æ•°æ®æ¢ç´¢ ---
print("\n=== æ•°æ®æ¢ç´¢ ===")
print("è®­ç»ƒæ•°æ®åŸºæœ¬ä¿¡æ¯:")
print(train_df.info())
print("\nç›®æ ‡å˜é‡åˆ†å¸ƒ:")
print(train_df['is_new_did'].value_counts())
print(f"æ–°å¢ç”¨æˆ·æ¯”ä¾‹: {train_df['is_new_did'].mean():.4f}")

print("\nç¼ºå¤±å€¼æƒ…å†µ:")
print("è®­ç»ƒæ•°æ®ç¼ºå¤±å€¼:")
print(train_df.isnull().sum())
print("\næµ‹è¯•æ•°æ®ç¼ºå¤±å€¼:")
print(test_df.isnull().sum())

# --- 3. ç‰¹å¾å·¥ç¨‹ ---
def extract_udmap_features(df):
    """ä»udmapå­—æ®µæå–ç‰¹å¾"""
    print("æå–udmapç‰¹å¾...")
    
    # åˆå§‹åŒ–æ–°ç‰¹å¾
    df['botId'] = np.nan
    df['pluginId'] = np.nan
    df['udmap_is_valid'] = 0
    
    for idx, udmap_str in enumerate(df['udmap']):
        if pd.isna(udmap_str) or udmap_str == '':
            continue
        try:
            udmap_dict = json.loads(udmap_str)
            if 'botId' in udmap_dict:
                df.loc[idx, 'botId'] = udmap_dict['botId']
            if 'pluginId' in udmap_dict:
                df.loc[idx, 'pluginId'] = udmap_dict['pluginId']
            df.loc[idx, 'udmap_is_valid'] = 1
        except:
            continue
    
    return df

def create_time_features(df):
    """åˆ›å»ºæ—¶é—´ç‰¹å¾"""
    print("åˆ›å»ºæ—¶é—´ç‰¹å¾...")
    
    # è½¬æ¢æ—¶é—´æˆ³
    df['common_ts'] = pd.to_datetime(df['common_ts'], unit='ms')
    
    # æå–æ—¶é—´ç‰¹å¾
    df['hour'] = df['common_ts'].dt.hour
    df['day_of_week'] = df['common_ts'].dt.dayofweek
    df['day_of_month'] = df['common_ts'].dt.day
    df['month'] = df['common_ts'].dt.month
    
    # æ—¶é—´æ®µç‰¹å¾
    df['time_period'] = pd.cut(df['hour'], 
                              bins=[0, 6, 12, 18, 24], 
                              labels=[0, 1, 2, 3], 
                              right=False).astype('int8')
    
    # æ˜¯å¦å·¥ä½œæ—¥
    df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')
    
    return df

def create_aggregation_features(df):
    """åˆ›å»ºèšåˆç‰¹å¾"""
    print("åˆ›å»ºèšåˆç‰¹å¾...")
    
    # ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ç‰¹å¾
    agg_features = []
    
    # æŒ‰didåˆ†ç»„çš„ç»Ÿè®¡ç‰¹å¾
    did_stats = df.groupby('did').agg({
        'mid': ['count', 'nunique'],
        'eid': ['count', 'nunique'],
        'device_brand': 'nunique',
        'common_ts': ['min', 'max']
    }).reset_index()
    
    # æ‰å¹³åŒ–åˆ—å
    did_stats.columns = ['did'] + ['_'.join(col).strip() for col in did_stats.columns[1:]]
    
    # è®¡ç®—æ—¶é—´è·¨åº¦
    did_stats['ts_span'] = (did_stats['common_ts_max'] - did_stats['common_ts_min']).dt.total_seconds()
    
    # åˆå¹¶åˆ°åŸæ•°æ®
    df = df.merge(did_stats, on='did', how='left')
    
    return df

def feature_engineering(df, is_train=True):
    """ç‰¹å¾å·¥ç¨‹ä¸»å‡½æ•°"""
    print(f"\n=== ç‰¹å¾å·¥ç¨‹ ({'è®­ç»ƒ' if is_train else 'æµ‹è¯•'}æ•°æ®) ===")
    
    # æå–udmapç‰¹å¾
    df = extract_udmap_features(df)
    
    # åˆ›å»ºæ—¶é—´ç‰¹å¾
    df = create_time_features(df)
    
    # åˆ›å»ºèšåˆç‰¹å¾
    df = create_aggregation_features(df)
    
    # å¤„ç†åˆ†ç±»ç‰¹å¾çš„ç¼ºå¤±å€¼
    categorical_cols = ['botId', 'pluginId']
    for col in categorical_cols:
        if col in df.columns:
            df[col] = df[col].fillna(-1).astype('int32')
    
    print(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {df.shape}")
    return df

# å¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®è¿›è¡Œç‰¹å¾å·¥ç¨‹
train_df = feature_engineering(train_df, is_train=True)
test_df = feature_engineering(test_df, is_train=False)

# --- 4. ç‰¹å¾é€‰æ‹© ---
# æ’é™¤ä¸éœ€è¦çš„ç‰¹å¾
exclude_features = ['did', 'udmap', 'common_ts', 'common_ts_min', 'common_ts_max']
if 'is_new_did' not in exclude_features:
    exclude_features.append('is_new_did')

feature_cols = [col for col in train_df.columns if col not in exclude_features]
print(f"\nä½¿ç”¨ç‰¹å¾æ•°é‡: {len(feature_cols)}")
print("ç‰¹å¾åˆ—è¡¨:", feature_cols)

# å‡†å¤‡è®­ç»ƒæ•°æ®
X = train_df[feature_cols]
y = train_df['is_new_did']
X_test = test_df[feature_cols]

print(f"è®­ç»ƒç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
print(f"æµ‹è¯•ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X_test.shape}")

# --- 5. F1åˆ†æ•°ä¼˜åŒ–å‡½æ•° ---
def find_best_threshold_f1(y_true, y_pred):
    """æ‰¾åˆ°ä½¿F1åˆ†æ•°æœ€å¤§çš„é˜ˆå€¼"""
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)
    f1_scores = 2 * recall * precision / (recall + precision + 1e-8)
    best_threshold_idx = np.argmax(f1_scores)
    best_threshold = thresholds[best_threshold_idx]
    best_f1 = f1_scores[best_threshold_idx]
    return best_threshold, best_f1

# --- 6. Optunaè´å¶æ–¯ä¼˜åŒ–è°ƒå‚ï¼ˆä¼˜åŒ–F1åˆ†æ•°ï¼‰---
print("\n=== Optunaè´å¶æ–¯ä¼˜åŒ–è°ƒå‚ï¼ˆä¼˜åŒ–F1åˆ†æ•°ï¼‰===")

def objective_f1(trial):
    """Optunaä¼˜åŒ–ç›®æ ‡å‡½æ•° - ä¼˜åŒ–F1åˆ†æ•°"""
    # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',  # ä½¿ç”¨loglossä½œä¸ºè®­ç»ƒæŒ‡æ ‡
        'boosting_type': 'gbdt',
        'verbosity': -1,
        'random_state': 42,
        'device': 'cuda',  # ä½¿ç”¨GPUåŠ é€Ÿ
        'gpu_platform_id': 0,  # GPUå¹³å°ID
        'gpu_device_id': 0,  # GPUè®¾å¤‡ID
        
        # ä¸ºF1ä¼˜åŒ–è°ƒæ•´çš„è¶…å‚æ•°èŒƒå›´
        'num_leaves': trial.suggest_int('num_leaves', 10, 300),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),
        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),
        'min_split_gain': trial.suggest_float('min_split_gain', 0, 1),
        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 50000, 300000),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        # ä¼˜åŒ–çš„è¶…å‚æ•°
        # é’ˆå¯¹F1ä¼˜åŒ–çš„é¢å¤–å‚æ•°
    }
    
    # 3æŠ˜äº¤å‰éªŒè¯è¯„ä¼°å‚æ•°
    skf_opt = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
    cv_f1_scores = []
    
    for train_idx, val_idx in skf_opt.split(X, y):
        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
        
        train_data = lgb.Dataset(X_train_fold, label=y_train_fold)
        val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)
        
        model = lgb.train(
            params,
            train_data,
            valid_sets=[val_data],
            num_boost_round=1000,
            callbacks=[
                lgb.early_stopping(stopping_rounds=50),
                lgb.log_evaluation(period=0)  # é™é»˜è®­ç»ƒ
            ]
        )
        
        val_pred = model.predict(X_val_fold, num_iteration=model.best_iteration)
        
        # æ‰¾åˆ°æœ€ä½³F1é˜ˆå€¼å¹¶è®¡ç®—F1åˆ†æ•°
        best_threshold, best_f1 = find_best_threshold_f1(y_val_fold, val_pred)
        cv_f1_scores.append(best_f1)
    
    return np.mean(cv_f1_scores)

# å¼€å§‹ä¼˜åŒ–
print("å¼€å§‹è´å¶æ–¯ä¼˜åŒ–ï¼ˆä¼˜åŒ–F1åˆ†æ•°ï¼‰...")
study_f1 = optuna.create_study(direction='maximize', 
                              sampler=optuna.samplers.TPESampler(seed=42),
                              pruner=optuna.pruners.MedianPruner())

study_f1.optimize(objective_f1, n_trials=100, timeout=3600)  # 100æ¬¡è¯•éªŒæˆ–1å°æ—¶è¶…æ—¶

print("ä¼˜åŒ–å®Œæˆï¼")
print(f"æœ€ä½³F1åˆ†æ•°: {study_f1.best_value:.6f}")
print("æœ€ä½³å‚æ•°:")
for key, value in study_f1.best_params.items():
    print(f"  {key}: {value}")

# ä½¿ç”¨æœ€ä½³å‚æ•°
best_params_f1 = study_f1.best_params.copy()
best_params_f1.update({
    'objective': 'binary',
    'metric': 'binary_logloss',
    'boosting_type': 'gbdt',
    'verbosity': -1,
    'random_state': 42,
    'device': 'cuda' if GPU_AVAILABLE else 'cpu',
    'gpu_platform_id': 0 if GPU_AVAILABLE else None,
    'gpu_device_id': 0 if GPU_AVAILABLE else None,
    'num_threads': 0 if GPU_AVAILABLE else -1,
})

# æ¸…ç†GPUæ¨¡å¼ä¸‹ä¸æ”¯æŒçš„å‚æ•°
if GPU_AVAILABLE:
    # ç§»é™¤å¯èƒ½å¯¼è‡´å†²çªçš„å‚æ•°
    params_to_remove = ['n_jobs']
    for param in params_to_remove:
        if param in best_params_f1:
            del best_params_f1[param]

# --- 7. ä½¿ç”¨æœ€ä½³å‚æ•°è¿›è¡Œæœ€ç»ˆè®­ç»ƒ ---
print("\n=== ä½¿ç”¨æœ€ä½³å‚æ•°è¿›è¡Œæœ€ç»ˆè®­ç»ƒï¼ˆF1ä¼˜åŒ–ï¼‰===")

# 5æŠ˜äº¤å‰éªŒè¯
n_fold = 5
skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)

oof_preds = np.zeros(len(X))
test_preds = np.zeros(len(X_test))
feature_importance = pd.DataFrame()
fold_f1_scores = []
fold_thresholds = []

print("å¼€å§‹äº¤å‰éªŒè¯è®­ç»ƒ...")
for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
    print(f"\n--- Fold {fold + 1} ---")
    
    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
    
    # åˆ›å»ºLightGBMæ•°æ®é›†
    train_data = lgb.Dataset(X_train_fold, label=y_train_fold)
    val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)
    
    # è®­ç»ƒæ¨¡å‹
    model = lgb.train(
        best_params_f1,
        train_data,
        valid_sets=[train_data, val_data],
        valid_names=['train', 'valid'],
        num_boost_round=2000,
        callbacks=[
            lgb.early_stopping(stopping_rounds=100),
            lgb.log_evaluation(period=100)
        ]
    )
    
    # é¢„æµ‹éªŒè¯é›†
    val_pred = model.predict(X_val_fold, num_iteration=model.best_iteration)
    oof_preds[val_idx] = val_pred
    
    # é¢„æµ‹æµ‹è¯•é›†
    test_pred = model.predict(X_test, num_iteration=model.best_iteration)
    test_preds += test_pred / n_fold
    
    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    fold_importance = pd.DataFrame()
    fold_importance['feature'] = X.columns
    fold_importance['importance'] = model.feature_importance(importance_type='gain')
    fold_importance['fold'] = fold + 1
    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)
    
    # è®¡ç®—è¯¥foldçš„æœ€ä½³F1åˆ†æ•°å’Œé˜ˆå€¼
    best_threshold, best_f1 = find_best_threshold_f1(y_val_fold, val_pred)
    fold_f1_scores.append(best_f1)
    fold_thresholds.append(best_threshold)
    
    # éªŒè¯é›†æ€§èƒ½
    val_auc = roc_auc_score(y_val_fold, val_pred)
    print(f"Fold {fold + 1} AUC: {val_auc:.6f}")
    print(f"Fold {fold + 1} F1: {best_f1:.6f} (threshold: {best_threshold:.4f})")

# --- 8. æ¨¡å‹è¯„ä¼° ---
print("\n=== æ¨¡å‹è¯„ä¼° ===")

# è®¡ç®—OOF AUC
oof_auc = roc_auc_score(y, oof_preds)
print(f"OOF AUC: {oof_auc:.6f}")

# è®¡ç®—OOFæœ€ä½³F1é˜ˆå€¼
oof_best_threshold, oof_best_f1 = find_best_threshold_f1(y, oof_preds)
print(f"OOFæœ€ä½³F1åˆ†æ•°: {oof_best_f1:.6f}")
print(f"OOFæœ€ä½³é˜ˆå€¼: {oof_best_threshold:.4f}")

# è®¡ç®—å„foldçš„å¹³å‡F1å’Œé˜ˆå€¼
avg_fold_f1 = np.mean(fold_f1_scores)
avg_fold_threshold = np.mean(fold_thresholds)
print(f"å„foldå¹³å‡F1åˆ†æ•°: {avg_fold_f1:.6f}")
print(f"å„foldå¹³å‡é˜ˆå€¼: {avg_fold_threshold:.4f}")

# ä½¿ç”¨OOFæœ€ä½³é˜ˆå€¼è¿›è¡Œåˆ†ç±»
oof_preds_binary = (oof_preds >= oof_best_threshold).astype(int)
oof_accuracy = accuracy_score(y, oof_preds_binary)
print(f"OOFå‡†ç¡®ç‡: {oof_accuracy:.6f}")

print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y, oof_preds_binary))

# --- 9. ç‰¹å¾é‡è¦æ€§åˆ†æ ---
print("\n=== ç‰¹å¾é‡è¦æ€§ ===")
feature_importance_agg = feature_importance.groupby('feature')['importance'].mean().sort_values(ascending=False)
print("Top 20 é‡è¦ç‰¹å¾:")
print(feature_importance_agg.head(20))

# --- 10. ç”Ÿæˆé¢„æµ‹ç»“æœ ---
print("\n=== ç”Ÿæˆé¢„æµ‹ç»“æœ ===")

# åˆ›å»ºä¿å­˜ç›®å½•
save_dir = "/home/joker/new_csdiylearning2/kfly/data/baseline3"
os.makedirs(save_dir, exist_ok=True)

# å‡†å¤‡æäº¤æ–‡ä»¶
submission = pd.DataFrame()
submission['did'] = test_df['did']
submission['is_new_did'] = test_preds

# ä½¿ç”¨OOFæœ€ä½³F1é˜ˆå€¼è¿›è¡ŒäºŒåˆ†ç±»
submission['is_new_did_binary'] = (test_preds >= oof_best_threshold).astype(int)

# ä¹Ÿå¯ä»¥ä½¿ç”¨å„foldå¹³å‡é˜ˆå€¼
submission['is_new_did_binary_avg'] = (test_preds >= avg_fold_threshold).astype(int)

print("é¢„æµ‹ç»“æœç»Ÿè®¡:")
print(f"é¢„æµ‹æ¦‚ç‡å‡å€¼: {test_preds.mean():.4f}")
print(f"é¢„æµ‹æ¦‚ç‡æ ‡å‡†å·®: {test_preds.std():.4f}")
print(f"é¢„æµ‹ä¸ºæ–°ç”¨æˆ·çš„æ¯”ä¾‹ï¼ˆOOFé˜ˆå€¼ï¼‰: {submission['is_new_did_binary'].mean():.4f}")
print(f"é¢„æµ‹ä¸ºæ–°ç”¨æˆ·çš„æ¯”ä¾‹ï¼ˆå¹³å‡é˜ˆå€¼ï¼‰: {submission['is_new_did_binary_avg'].mean():.4f}")

# ä¿å­˜ç»“æœ
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
submission_filename = os.path.join(save_dir, f"submission_lgb_f1_optuna_{timestamp}.csv")
binary_filename = os.path.join(save_dir, f"submission_lgb_f1_binary_optuna_{timestamp}.csv")
binary_avg_filename = os.path.join(save_dir, f"submission_lgb_f1_binary_avg_optuna_{timestamp}.csv")

# ä¿å­˜æ¦‚ç‡é¢„æµ‹ç»“æœ
submission[['did', 'is_new_did']].to_csv(submission_filename, index=False)
print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {submission_filename}")

# ä¿å­˜F1ä¼˜åŒ–çš„äºŒåˆ†ç±»ç»“æœï¼ˆOOFé˜ˆå€¼ï¼‰
submission[['did', 'is_new_did_binary']].rename(columns={'is_new_did_binary': 'is_new_did'}).to_csv(binary_filename, index=False)
print(f"F1ä¼˜åŒ–äºŒåˆ†ç±»ç»“æœï¼ˆOOFé˜ˆå€¼ï¼‰å·²ä¿å­˜è‡³: {binary_filename}")

# ä¿å­˜F1ä¼˜åŒ–çš„äºŒåˆ†ç±»ç»“æœï¼ˆå¹³å‡é˜ˆå€¼ï¼‰
submission[['did', 'is_new_did_binary_avg']].rename(columns={'is_new_did_binary_avg': 'is_new_did'}).to_csv(binary_avg_filename, index=False)
print(f"F1ä¼˜åŒ–äºŒåˆ†ç±»ç»“æœï¼ˆå¹³å‡é˜ˆå€¼ï¼‰å·²ä¿å­˜è‡³: {binary_avg_filename}")

# ä¿å­˜ä¼˜åŒ–å†å²å’Œæœ€ä½³å‚æ•°
optuna_results_f1 = {
    'best_f1': study_f1.best_value,
    'best_params': study_f1.best_params,
    'final_oof_auc': oof_auc,
    'final_oof_f1': oof_best_f1,
    'oof_best_threshold': oof_best_threshold,
    'fold_avg_f1': avg_fold_f1,
    'fold_avg_threshold': avg_fold_threshold,
    'optimization_trials': len(study_f1.trials)
}

import pickle
optuna_filename = os.path.join(save_dir, f"optuna_f1_study_{timestamp}.pkl")
with open(optuna_filename, 'wb') as f:
    pickle.dump(study_f1, f)
print(f"Optuna F1ä¼˜åŒ–ç ”ç©¶ç»“æœå·²ä¿å­˜è‡³: {optuna_filename}")

# ä¿å­˜ç‰¹å¾é‡è¦æ€§
feature_importance_agg = feature_importance.groupby('feature')['importance'].mean().sort_values(ascending=False)
feature_importance_filename = os.path.join(save_dir, f"feature_importance_f1_{timestamp}.csv")
feature_importance_agg.to_csv(feature_importance_filename)
print(f"ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜è‡³: {feature_importance_filename}")

# ä¿å­˜é˜ˆå€¼ä¿¡æ¯
threshold_info = pd.DataFrame({
    'fold': list(range(1, n_fold + 1)) + ['OOF', 'Average'],
    'f1_score': fold_f1_scores + [oof_best_f1, avg_fold_f1],
    'threshold': fold_thresholds + [oof_best_threshold, avg_fold_threshold]
})
threshold_filename = os.path.join(save_dir, f"f1_thresholds_{timestamp}.csv")
threshold_info.to_csv(threshold_filename, index=False)
print(f"F1é˜ˆå€¼ä¿¡æ¯å·²ä¿å­˜è‡³: {threshold_filename}")

print("\n=== F1ä¼˜åŒ–åŸºçº¿æ¨¡å‹å®Œæˆ ===")
print(f"ä½¿ç”¨è®¾å¤‡: {'GPU' if GPU_AVAILABLE else 'CPU'}")
print(f"Optunaæœ€ä½³éªŒè¯F1: {study_f1.best_value:.6f}")
print(f"æœ€ç»ˆæ¨¡å‹OOF AUC: {oof_auc:.6f}")
print(f"æœ€ç»ˆæ¨¡å‹OOF F1: {oof_best_f1:.6f}")
print(f"æœ€ç»ˆæ¨¡å‹æœ€ä½³é˜ˆå€¼: {oof_best_threshold:.4f}")
print(f"ä½¿ç”¨äº† {len(feature_cols)} ä¸ªç‰¹å¾")
print(f"ä¼˜åŒ–è¯•éªŒæ¬¡æ•°: {len(study_f1.trials)}")
print("\né’ˆå¯¹F1ä¼˜åŒ–çš„æ”¹è¿›:")
print("1. ä¼˜åŒ–ç›®æ ‡ä»AUCæ”¹ä¸ºF1åˆ†æ•°")
print("2. å¢åŠ äº†scale_pos_weightå’Œis_unbalanceå‚æ•°ä¼˜åŒ–")
print("3. ä¸ºæ¯ä¸ªfoldè®¡ç®—æœ€ä½³F1é˜ˆå€¼")
print("4. æä¾›äº†å¤šç§é˜ˆå€¼é€‰æ‹©ç­–ç•¥")
print("5. ä¿å­˜äº†è¯¦ç»†çš„F1å’Œé˜ˆå€¼ä¿¡æ¯")
if GPU_AVAILABLE:
    print("6. ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒï¼Œæ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦")
    print("7. ğŸ¯ GPUç‰¹å®šå‚æ•°ä¼˜åŒ–ï¼ˆgpu_use_dpç­‰ï¼‰")
print("\nå»ºè®®åç»­ä¼˜åŒ–æ–¹å‘:")
print("1. ç‰¹å¾å·¥ç¨‹ï¼šæ›´å¤šæ—¶é—´çª—å£ç»Ÿè®¡ç‰¹å¾ã€ç”¨æˆ·è¡Œä¸ºåºåˆ—ç‰¹å¾")
print("2. æ¨¡å‹èåˆï¼šXGBoostã€CatBoostç­‰æ¨¡å‹é›†æˆ")
print("3. ç±»åˆ«å¹³è¡¡ï¼šSMOTEã€éšæœºæ¬ é‡‡æ ·ç­‰æŠ€æœ¯")
print("4. é˜ˆå€¼ç­–ç•¥ï¼šåŠ¨æ€é˜ˆå€¼ã€åŸºäºéªŒè¯é›†çš„é˜ˆå€¼é€‰æ‹©")
print("5. é›†æˆå­¦ä¹ ï¼šå¤šä¸ªF1ä¼˜åŒ–æ¨¡å‹çš„ensemble")
if GPU_AVAILABLE:
    print("6. GPUä¼˜åŒ–ï¼šè°ƒæ•´gpu_use_dpã€å¢åŠ GPUå†…å­˜ä½¿ç”¨æ•ˆç‡")
    print("7. å¹¶è¡Œè®­ç»ƒï¼šå¤šGPUè®­ç»ƒã€åˆ†å¸ƒå¼è®­ç»ƒ")
else:
    print("6. GPUåŠ é€Ÿï¼šå®‰è£…GPUç‰ˆæœ¬LightGBMè·å¾—æ›´å¿«è®­ç»ƒé€Ÿåº¦")